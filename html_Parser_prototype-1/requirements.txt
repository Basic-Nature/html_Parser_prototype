# filepath: c:\Users\olivi\OneDrive\Desktop\html_Parser_prototype\webapp\parser\html_election_parser.py

from playwright.sync_api import Page
from .utils.shared_logger import logger
from .utils.html_scanner import scan_html_for_context, get_detected_races_from_context
from .utils.contest_selector import select_contest
from .utils.table_builder import extract_table_data
from .utils.output_utils import finalize_election_output
from .utils.format_router import route_format_handler
from .state_router import get_handler_from_context
import re

def orchestrate_parsing(page: Page, html_context=None):
    """
    Orchestrates the entire election data parsing pipeline.
    
    Args:
        page (Page): The Playwright page object containing the election data.
        html_context (dict): Optional context for the HTML parsing.
    """
    # Step 1: Scan the page for context and races
    context = scan_html_for_context(page)
    if html_context is None:
        html_context = {}
    html_context.update(context)

    # Step 2: Delegate to state/county handler if available
    state_handler = get_handler_from_context(
        state=html_context.get("state"),
        county=html_context.get("county")
    )
    if state_handler and hasattr(state_handler, "parse"):
        logger.info("[INFO] Delegating to state handler for parsing.")
        state_handler.parse(page, html_context)
        return

    # Step 3: Let user select contest if not already set
    contest_title = html_context.get("selected_race")
    if not contest_title:
        contest_title = select_contest(get_detected_races_from_context(context))
        if contest_title is None:
            logger.warning("[WARN] No contest selected. Skipping parsing.")
            return

    # Step 4: Extract contest panel and precinct tables
    contest_panel = extract_contest_panel(page, contest_title)
    precinct_tables = extract_precinct_tables(contest_panel)

    # Step 5: Parse each precinct table and collect data
    all_data = []
    for precinct_name, table_element in precinct_tables:
        headers, data = extract_table_data(table_element)
        all_data.extend(data)

    # Step 6: Finalize output
    if all_data:
        metadata = {
            "state": html_context.get("state"),
            "county": html_context.get("county"),
            "contest_title": contest_title
        }
        headers = headers  # Assuming headers are consistent across tables
        finalize_election_output(headers, all_data, contest_title, metadata)
    else:
        logger.warning("[WARN] No data extracted from precinct tables.")

def extract_contest_panel(page, contest_title):
    """
    Extracts the contest panel from the page based on the contest title.
    
    Args:
        page (Page): The Playwright page object.
        contest_title (str): The title of the contest to extract.
    
    Returns:
        Playwright Locator: The contest panel element.
    """
    # Implementation of extracting the contest panel
    # (This function should be defined based on your existing logic)
    pass

def extract_precinct_tables(panel):
    """
    Extracts precinct tables from the contest panel.
    
    Args:
        panel: The contest panel element.
    
    Returns:
        List of tuples containing precinct names and their corresponding table elements.
    """
    # Implementation of extracting precinct tables
    # (This function should be defined based on your existing logic)
    pass

def main(page: Page):
    """
    Main entry point for the HTML election parser.
    
    Args:
        page (Page): The Playwright page object containing the election data.
    """
    logger.info("[INFO] Starting the election data parsing pipeline.")
    orchestrate_parsing(page)

# Example usage
# if __name__ == "__main__":
#     with sync_playwright() as playwright:
#         browser = playwright.chromium.launch()
#         page = browser.new_page()
#         page.goto("URL_OF_ELECTION_DATA")
#         main(page)
#         browser.close()